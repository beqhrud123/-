{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beqhrud123/-/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnb1Bssc6-S",
        "outputId": "2c19719a-bb85-48c3-e42a-dca34f7b6889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<현재 상영중인 영화 랭킹>>\n",
            "01 범죄도시2 9.55\n",
            "---------------\n",
            "---------------\n",
            "01 범죄도시2 9.55\n",
            "02 씽2게더 9.39\n",
            "03 극장판 귀멸의 칼날: 무한열차편 9.27\n",
            "04 극장판 주술회전 0 9.25\n",
            "05 해피 투게더 9.19\n",
            "06 코다 9.13\n",
            "07 중경삼림 8.90\n",
            "08 화양연화 8.81\n",
            "09 아메리칸 셰프 8.75\n",
            "010 배드 가이즈 8.67\n",
            "---------------\n",
            "11 걸어도 걸어도 8.63\n",
            "12 라라랜드 8.62\n",
            "13 공기살인 8.49\n",
            "14 아비정전 8.44\n",
            "15 드라이브 마이 카 8.41\n",
            "16 모가디슈 8.33\n",
            "17 어나더 라운드 8.30\n",
            "18 수퍼 소닉2 8.26\n",
            "19 경계선 8.20\n",
            "20 언어의 정원 8.18\n",
            "---------------\n",
            "21 날씨의 아이 7.96\n",
            "22 니 부모 얼굴이 보고 싶다 7.72\n",
            "23 스펜서 7.72\n",
            "24 그대가 조국 7.54\n",
            "25 디어 에반 핸슨 7.47\n",
            "26 민스미트 작전 7.35\n",
            "27 닥터 스트레인지: 대혼돈의 멀티버스 7.32\n",
            "28 아사코 7.28\n",
            "29 신비한 동물들과 덤블도어의 비밀 6.53\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cur&date=20220530'\n",
        "data = requests.get(url)\n",
        "soup = bs(data.text)\n",
        "\n",
        "meta = soup.find_all('meta')\n",
        "\n",
        "IstRanking = soup.find(\"table\",{\"class\":\"list_ranking\"})\n",
        "\n",
        "div = IstRanking.find('div',{'class':'tit5'})\n",
        "title = div.find('a')['title']\n",
        "point = IstRanking.find('td',{'class':'point'})\n",
        "acClass = IstRanking.find('td',{'class':'ac'})\n",
        "rank = acClass.find('img')['alt']\n",
        "print('<<현재 상영중인 영화 랭킹>>')\n",
        "print(rank, title, point.text)\n",
        "\n",
        "trTag = IstRanking.findAll('tr')\n",
        "for Li in trTag[:33]:\n",
        "        try:\n",
        "           info = Li.find(\"div\", {\"class\": 'tit5'})\n",
        "           aTag = info.find('a')\n",
        "           title = aTag['title']\n",
        "\n",
        "           acCLass = Li.find('td',{'class':'ac'})\n",
        "           rank = acCLass.find('img')['alt']\n",
        "\n",
        "           point = Li.find('td',{'class':'point'})\n",
        "           point = point.text\n",
        "\n",
        "           print(rank, title, point)\n",
        "        except Exception as e:\n",
        "           print('---------------')\n",
        "#return {'rank':rank, 'title':title, 'point':point}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import bs4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "need_reviews_cnt = 100\n",
        "reviews = []\n",
        "review_data=[]\n",
        "\n",
        "for page in range(1,50):\n",
        "    url = f'https://movie.naver.com/movie/point/af/list.naver?&page={page}'\n",
        "    html = requests.get(url)\n",
        "    soup = BeautifulSoup(html.content,'html.parser')\n",
        "    reviews = soup.find_all(\"td\",{\"class\":\"title\"})\n",
        "    \n",
        "    for review in reviews:\n",
        "        sentence = review.find(\"a\",{\"class\":\"report\"}).get(\"onclick\").split(\"', '\")[2]\n",
        "        if sentence != \"\":\n",
        "            movie = review.find(\"a\",{\"class\":\"movie color_b\"}).get_text()\n",
        "            score = review.find(\"em\").get_text()\n",
        "            review_data.append([movie,sentence,int(score)])\n",
        "            need_reviews_cnt-= 1     \n",
        "    if need_reviews_cnt < 0:                                         \n",
        "        break\n",
        "\n",
        "columns_name = [\"movie\",\"sentence\",\"score\"]\n",
        "with open ( \"samples.csv\", \"w\", newline =\"\",encoding = 'utf8' ) as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(columns_name)\n",
        "    write.writerows(review_data)"
      ],
      "metadata": {
        "id": "TM3OnHHpevhB"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}